{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fsevkli/phish-ai/blob/main/Project_432.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L61ZwNDhRajK",
        "outputId": "b4d6b547-1bc4-4b9a-eeed-67641baa810f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0mGemini configured from env\n",
            "HF shape: (18650, 2)\n",
            "Kaggle shape: (18650, 2)\n",
            "Train/Val/Test sizes: 13055 2797 2798\n",
            "Using device: cuda\n",
            "Embedding shapes - Train: (13055, 384) Test: (2798, 384)\n",
            "Loaded calibrated model from phishing_ai/calibrated_model_v1.joblib\n",
            "\n",
            "Kaggle dataset performance:\n",
            "  Accuracy : 0.951 (95.1%)\n",
            "  Precision: 0.931\n",
            "  Recall   : 0.946\n",
            "  F1 Score : 0.938\n",
            "\n",
            "------------------------------------------------------------\n",
            "EMAIL PREVIEW:\n",
            " a permanent solution to penis enlargement limited offer : increase atleast 3 inches or get your money back ! - - - - > click here to learn more no more offers ...\n",
            "\n",
            "True label : phishing\n",
            "Predicted  : phishing (p=0.96, risk=HIGH)\n",
            "\n",
            "Gemini explanation:\n",
            "ðŸš© **HIGH RISK**: This email is a phishing attempt designed to trick you. It uses urgency to pressure you into clicking a suspicious link. **Do not click any links.**\n",
            "\n",
            "------------------------------------------------------------\n",
            "EMAIL PREVIEW:\n",
            " Get your favorite Poker action at http://www.multiplayerpoker.netPlay against real people from around the world for real money or just\n",
            "for fun.  Access one of the busiest poker rooms online.  We've dealt\n",
            "over 8 million hands!  Experience the best poker software available\n",
            "today featuring world class graphics, true random shuffling algorithms,\n",
            "and 24x7 customer service.  We've got a great selection  ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 328.17ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label : phishing\n",
            "Predicted  : phishing (p=0.90, risk=HIGH)\n",
            "\n",
            "Gemini explanation:\n",
            "Could not generate explanation: 403 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint: Your API key was reported as leaked. Please use another API key.\n",
            "\n",
            "------------------------------------------------------------\n",
            "EMAIL PREVIEW:\n",
            " re [ 1 ] : ave ! hello my dear ! i am a lovely and lonely lady who is looking for the man who will make me happy and whom i want to feel like in paradise with ! if you want to be my beautiful hero who will save me from this loneliness find me http : / / www . yqryjv 5 iqxc . hellomylove . net / and wake me up with a warm kiss . goodbye . . . . . juliana ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 327.91ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label : phishing\n",
            "Predicted  : phishing (p=0.93, risk=HIGH)\n",
            "\n",
            "Gemini explanation:\n",
            "Could not generate explanation: 403 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint: Your API key was reported as leaked. Please use another API key.\n",
            "\n",
            "------------------------------------------------------------\n",
            "EMAIL PREVIEW:\n",
            " replacing our people who have left louise - - is it appropriate to replace the people who have left ( steve walton and susan scott lindberg ) with other people that can do the work ? jim ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 327.98ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label : benign\n",
            "Predicted  : benign (p=0.02, risk=LOW)\n",
            "\n",
            "Gemini explanation:\n",
            "Could not generate explanation: 403 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint: Your API key was reported as leaked. Please use another API key.\n",
            "\n",
            "------------------------------------------------------------\n",
            "EMAIL PREVIEW:\n",
            " From: Matt Kettler > Hmm, I think that Marc, being one of the most active and prolific posters \n",
            "> to this list, certainly understands SA much better than most. Certainly Frequency of messages does _not_ let you draw valid conclusions about the\n",
            "understanding of the issues at hand of the sender.\n",
            "IMHO it's sometimes even inversely proportional.> Marc is an active and prolific contributor to SA (gee,  ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 328.05ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label : benign\n",
            "Predicted  : benign (p=0.02, risk=LOW)\n",
            "\n",
            "Gemini explanation:\n",
            "Could not generate explanation: 403 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint: Your API key was reported as leaked. Please use another API key.\n",
            "\n",
            "Pipeline complete (cached artifacts in phishing_ai )\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ===============================================================\n",
        "# Phishing Email Detection with Hybrid Model & Explanations (Colab-ready)\n",
        "# Caches data/splits/embeddings/models to avoid re-running on Colab.\n",
        "# ===============================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Optional: lightweight installs when running in Colab\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        import IPython\n",
        "        IPython.get_ipython().run_line_magic(\n",
        "            \"pip\",\n",
        "            \"install -q datasets sentence-transformers scikit-learn google-generativeai kagglehub joblib faiss-gpu\",\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"pip install skipped:\", e)\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    brier_score_loss,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "import google.generativeai as genai\n",
        "import kagglehub\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
        "\n",
        "# ===============================================================\n",
        "# 1. CONFIG + GEMINI API SETUP (env-based)\n",
        "# ===============================================================\n",
        "\n",
        "#GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "if GEMINI_API_KEY:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    gemini_model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "    print(\"Gemini configured from env\")\n",
        "else:\n",
        "    gemini_model = None\n",
        "    print(\"WARNING: GEMINI_API_KEY not set; explanations will use a fallback string.\")\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive\") if Path(\"/content/drive\").exists() else Path(\".\")\n",
        "ARTIFACT_DIR = Path(os.getenv(\"ARTIFACT_DIR\", DRIVE_ROOT / \"phishing_ai\")).expanduser()\n",
        "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "VERSION = \"v1\"\n",
        "\n",
        "hf_cache = ARTIFACT_DIR / f\"hf_clean_{VERSION}.csv\"\n",
        "kaggle_cache = ARTIFACT_DIR / f\"kaggle_clean_{VERSION}.csv\"\n",
        "split_cache = ARTIFACT_DIR / f\"splits_{VERSION}.npz\"\n",
        "model_path = ARTIFACT_DIR / f\"calibrated_model_{VERSION}.joblib\"\n",
        "train_emb_path = ARTIFACT_DIR / f\"train_emb_{VERSION}.npy\"\n",
        "val_emb_path = ARTIFACT_DIR / f\"val_emb_{VERSION}.npy\"\n",
        "test_emb_path = ARTIFACT_DIR / f\"test_emb_{VERSION}.npy\"\n",
        "kaggle_emb_path = ARTIFACT_DIR / f\"kaggle_emb_{VERSION}.npy\"\n",
        "\n",
        "# ===============================================================\n",
        "# 2. DATA LOAD + CLEAN (with caching)\n",
        "# ===============================================================\n",
        "\n",
        "def load_hf_dataset():\n",
        "    if hf_cache.exists():\n",
        "        return pd.read_csv(hf_cache)\n",
        "    ds = load_dataset(\"zefang-liu/phishing-email-dataset\")\n",
        "    df = pd.DataFrame(ds[\"train\"])\n",
        "    if \"Unnamed: 0\" in df.columns:\n",
        "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
        "    if \"Email Text\" in df.columns:\n",
        "        df = df.rename(columns={\"Email Text\": \"email\"})\n",
        "    elif \"text\" in df.columns:\n",
        "        df = df.rename(columns={\"text\": \"email\"})\n",
        "    if \"Email Type\" in df.columns:\n",
        "        df = df.rename(columns={\"Email Type\": \"label\"})\n",
        "    df[\"email\"] = df[\"email\"].astype(str).fillna(\"\")\n",
        "    if df[\"label\"].dtype == object:\n",
        "        df[\"label\"] = df[\"label\"].str.contains(\"phish\", case=False).astype(int)\n",
        "    df = df[[\"email\", \"label\"]]\n",
        "    df.to_csv(hf_cache, index=False)\n",
        "    return df\n",
        "\n",
        "def load_kaggle_dataset():\n",
        "    if kaggle_cache.exists():\n",
        "        return pd.read_csv(kaggle_cache)\n",
        "    path = kagglehub.dataset_download(\"subhajournal/phishingemails\")\n",
        "    csv_files = [f for f in os.listdir(path) if f.lower().endswith(\".csv\")]\n",
        "    csv_path = os.path.join(path, csv_files[0])\n",
        "    raw = pd.read_csv(csv_path)\n",
        "    if \"Email Text\" in raw.columns and \"Email Type\" in raw.columns:\n",
        "        df = pd.DataFrame({\n",
        "            \"email\": raw[\"Email Text\"].astype(str),\n",
        "            \"label\": raw[\"Email Type\"].str.contains(\"phish\", case=False).astype(int),\n",
        "        })\n",
        "    else:\n",
        "        text_col, label_col = raw.columns[:2]\n",
        "        df = pd.DataFrame({\n",
        "            \"email\": raw[text_col].astype(str),\n",
        "            \"label\": raw[label_col].astype(int),\n",
        "        })\n",
        "    df[\"email\"] = df[\"email\"].fillna(\"\")\n",
        "    df.to_csv(kaggle_cache, index=False)\n",
        "    return df\n",
        "\n",
        "df_hf = load_hf_dataset()\n",
        "df_kaggle = load_kaggle_dataset()\n",
        "print(\"HF shape:\", df_hf.shape)\n",
        "print(\"Kaggle shape:\", df_kaggle.shape)\n",
        "\n",
        "# ===============================================================\n",
        "# 3. FEATURE ENGINEERING\n",
        "# ===============================================================\n",
        "\n",
        "class PhishingFeatureExtractor:\n",
        "    def __init__(self):\n",
        "        self.urgency_keywords = [\n",
        "            \"urgent\", \"immediately\", \"action required\", \"verify now\",\n",
        "            \"suspended\", \"expired\", \"limited time\", \"act now\",\n",
        "            \"confirm\", \"click here\", \"final notice\", \"warning\",\n",
        "            \"alert\", \"attention\", \"important\", \"asap\",\n",
        "        ]\n",
        "        self.cred_keywords = [\n",
        "            \"password\", \"login\", \"username\", \"account\", \"verify\",\n",
        "            \"update payment\", \"billing\", \"credit card\", \"ssn\",\n",
        "            \"social security\", \"bank\", \"paypal\", \"gift card\",\n",
        "            \"confirm identity\", \"security question\",\n",
        "        ]\n",
        "\n",
        "    def extract_all(self, text: str):\n",
        "        if text is None or (isinstance(text, float) and np.isnan(text)):\n",
        "          text = \"\"\n",
        "        text = str(text)\n",
        "        t = text.lower()\n",
        "        urg_hits = [kw for kw in self.urgency_keywords if kw in t]\n",
        "        cred_hits = [kw for kw in self.cred_keywords if kw in t]\n",
        "        urls = re.findall(r\"https?://[^\\s]+\", text)\n",
        "        ip_links = re.findall(r\"https?://\\d{1,3}(?:\\.\\d{1,3}){3}\", text)\n",
        "        long_urls = [u for u in urls if len(u) > 50]\n",
        "        encoded_urls = [u for u in urls if \"%\" in u]\n",
        "        sus_tlds = [\".tk\", \".ml\", \".ga\", \".cf\", \".gq\", \".xyz\"]\n",
        "        sus_urls = [u for u in urls for tld in sus_tlds if tld in u.lower()]\n",
        "        caps_words = re.findall(r\"\\b[A-Z]{3,}\\b\", text)\n",
        "        feats = {\n",
        "            \"urgency_count\": len(urg_hits),\n",
        "            \"exclamations\": text.count(\"!\"),\n",
        "            \"caps_count\": len(caps_words),\n",
        "            \"multi_exclam\": len(re.findall(r\"!{2,}\", text)),\n",
        "            \"cred_count\": len(cred_hits),\n",
        "            \"has_form_language\": int(bool(re.search(r\"enter your|provide your|update your|fill out\", t))),\n",
        "            \"url_count\": len(urls),\n",
        "            \"ip_url_count\": len(ip_links),\n",
        "            \"long_url_count\": len(long_urls),\n",
        "            \"encoded_url_count\": len(encoded_urls),\n",
        "            \"sus_tld_count\": len(sus_urls),\n",
        "        }\n",
        "        details = {\n",
        "            \"urgency_hits\": urg_hits,\n",
        "            \"cred_hits\": cred_hits,\n",
        "            \"urls\": urls[:3],\n",
        "            \"ip_links\": ip_links,\n",
        "            \"caps_words\": caps_words[:5],\n",
        "        }\n",
        "        return feats, details\n",
        "\n",
        "    def transform(self, texts):\n",
        "        feat_list, details_list = [], []\n",
        "        for txt in texts:\n",
        "            f, d = self.extract_all(txt)\n",
        "            feat_list.append(f)\n",
        "            details_list.append(d)\n",
        "        return pd.DataFrame(feat_list), details_list\n",
        "\n",
        "feature_extractor = PhishingFeatureExtractor()\n",
        "feat_df_hf, feat_details_hf = feature_extractor.transform(df_hf[\"email\"].values)\n",
        "feat_df_k, feat_details_k = feature_extractor.transform(df_kaggle[\"email\"].values)\n",
        "\n",
        "# ===============================================================\n",
        "# 4. TRAIN/VAL/TEST SPLIT (cached indices)\n",
        "# ===============================================================\n",
        "\n",
        "def get_splits(labels):\n",
        "    if split_cache.exists():\n",
        "        data = np.load(split_cache, allow_pickle=True)\n",
        "        return data[\"train_idx\"], data[\"val_idx\"], data[\"test_idx\"]\n",
        "    idx = np.arange(len(labels))\n",
        "    train_idx, temp_idx, y_train_temp, y_temp = train_test_split(\n",
        "        idx, labels, test_size=0.30, stratify=labels, random_state=42\n",
        "    )\n",
        "    val_idx, test_idx, _, _ = train_test_split(\n",
        "        temp_idx, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
        "    )\n",
        "    np.savez(split_cache, train_idx=train_idx, val_idx=val_idx, test_idx=test_idx)\n",
        "    return train_idx, val_idx, test_idx\n",
        "\n",
        "train_idx, val_idx, test_idx = get_splits(df_hf[\"label\"].values)\n",
        "\n",
        "X_train_email = df_hf[\"email\"].values[train_idx]\n",
        "X_val_email = df_hf[\"email\"].values[val_idx]\n",
        "X_test_email = df_hf[\"email\"].values[test_idx]\n",
        "\n",
        "y_train = df_hf[\"label\"].values[train_idx]\n",
        "y_val = df_hf[\"label\"].values[val_idx]\n",
        "y_test = df_hf[\"label\"].values[test_idx]\n",
        "\n",
        "X_train_feat = feat_df_hf.values[train_idx]\n",
        "X_val_feat = feat_df_hf.values[val_idx]\n",
        "X_test_feat = feat_df_hf.values[test_idx]\n",
        "\n",
        "print(\"Train/Val/Test sizes:\", len(y_train), len(y_val), len(y_test))\n",
        "\n",
        "# ===============================================================\n",
        "# 5. MINI LM EMBEDDINGS (cached to disk)\n",
        "# ===============================================================\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "sentence_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def encode_batch(texts, batch_size=128):\n",
        "    return sentence_model.encode(\n",
        "        list(texts),\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=False,\n",
        "    )\n",
        "\n",
        "def encode_cached(name, texts, path):\n",
        "    if path.exists():\n",
        "        return np.load(path)\n",
        "    arr = encode_batch(texts)\n",
        "    np.save(path, arr)\n",
        "    return arr\n",
        "\n",
        "X_train_emb = encode_cached(\"train\", X_train_email, train_emb_path)\n",
        "X_val_emb = encode_cached(\"val\", X_val_email, val_emb_path)\n",
        "X_test_emb = encode_cached(\"test\", X_test_email, test_emb_path)\n",
        "X_k_emb = encode_cached(\"kaggle\", df_kaggle[\"email\"].values, kaggle_emb_path)\n",
        "\n",
        "print(\"Embedding shapes - Train:\", X_train_emb.shape, \"Test:\", X_test_emb.shape)\n",
        "\n",
        "# ===============================================================\n",
        "# 6. TRAIN HYBRID MODEL (with calibration) + LOAD IF AVAILABLE\n",
        "# ===============================================================\n",
        "\n",
        "X_train_hybrid = np.hstack([X_train_feat, X_train_emb])\n",
        "X_test_hybrid = np.hstack([X_test_feat, X_test_emb])\n",
        "X_k_hybrid = np.hstack([feat_df_k.values, X_k_emb])\n",
        "\n",
        "if model_path.exists():\n",
        "    best_model = joblib.load(model_path)\n",
        "    print(\"Loaded calibrated model from\", model_path)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TRAINING HYBRID MODEL (Features + MiniLM)\")\n",
        "    print(\"=\"*60)\n",
        "    base_clf = LogisticRegression(max_iter=2000, random_state=42)\n",
        "    base_clf.fit(X_train_hybrid, y_train)\n",
        "    y_pred = base_clf.predict(X_test_hybrid)\n",
        "    y_prob = base_clf.predict_proba(X_test_hybrid)[:, 1]\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(\"\\nTest set performance (uncalibrated):\")\n",
        "    print(f\"  Accuracy : {acc:.3f} ({acc*100:.1f}%)\")\n",
        "    print(f\"  Precision: {prec:.3f}\")\n",
        "    print(f\"  Recall   : {rec:.3f}\")\n",
        "    print(f\"  F1 Score : {f1:.3f}\")\n",
        "    print(f\"  Confusion: TN={cm[0,0]}, FP={cm[0,1]}, FN={cm[1,0]}, TP={cm[1,1]}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CALIBRATING MODEL\")\n",
        "    print(\"=\"*60)\n",
        "    calibrated_model = CalibratedClassifierCV(\n",
        "        LogisticRegression(max_iter=2000, random_state=42),\n",
        "        cv=5,\n",
        "        method=\"sigmoid\",\n",
        "    )\n",
        "    calibrated_model.fit(X_train_hybrid, y_train)\n",
        "\n",
        "    y_prob_cal = calibrated_model.predict_proba(X_test_hybrid)[:, 1]\n",
        "    brier_uncal = brier_score_loss(y_test, y_prob)\n",
        "    brier_cal = brier_score_loss(y_test, y_prob_cal)\n",
        "    print(f\"Brier Score (uncalibrated): {brier_uncal:.4f}\")\n",
        "    print(f\"Brier Score (calibrated)  : {brier_cal:.4f}\")\n",
        "\n",
        "    # Calibration curves\n",
        "    pt_u, pp_u = calibration_curve(y_test, y_prob, n_bins=10)\n",
        "    pt_c, pp_c = calibration_curve(y_test, y_prob_cal, n_bins=10)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    ax1.plot(pp_u, pt_u, \"o-\", label=\"Uncalibrated\", linewidth=2)\n",
        "    ax1.plot(pp_c, pt_c, \"s-\", label=\"Calibrated\", linewidth=2)\n",
        "    ax1.plot([0, 1], [0, 1], \"k--\", label=\"Perfect\", alpha=0.5)\n",
        "    ax1.set_xlabel(\"Mean predicted probability\")\n",
        "    ax1.set_ylabel(\"Fraction of positives\")\n",
        "    ax1.set_title(\"Reliability Diagram\")\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ConfusionMatrixDisplay(cm, display_labels=[\"Benign\", \"Phishing\"]).plot(ax=ax2, cmap=\"Blues\")\n",
        "    ax2.set_title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    best_model = calibrated_model\n",
        "    joblib.dump(best_model, model_path)\n",
        "    print(\"Saved calibrated model to\", model_path)\n",
        "\n",
        "# ===============================================================\n",
        "# 7. ROBUSTNESS TEST ON KAGGLE DATASET\n",
        "# ===============================================================\n",
        "\n",
        "y_k_pred = best_model.predict(X_k_hybrid)\n",
        "y_k_prob = best_model.predict_proba(X_k_hybrid)[:, 1]\n",
        "acc_k = accuracy_score(df_kaggle[\"label\"].values, y_k_pred)\n",
        "prec_k = precision_score(df_kaggle[\"label\"].values, y_k_pred)\n",
        "rec_k = recall_score(df_kaggle[\"label\"].values, y_k_pred)\n",
        "f1_k = f1_score(df_kaggle[\"label\"].values, y_k_pred)\n",
        "\n",
        "print(\"\\nKaggle dataset performance:\")\n",
        "print(f\"  Accuracy : {acc_k:.3f} ({acc_k*100:.1f}%)\")\n",
        "print(f\"  Precision: {prec_k:.3f}\")\n",
        "print(f\"  Recall   : {rec_k:.3f}\")\n",
        "print(f\"  F1 Score : {f1_k:.3f}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 8. GEMINI EXPLANATIONS + INFERENCE WRAPPERS\n",
        "# ===============================================================\n",
        "\n",
        "def gemini_explain(email_text: str, prob_phish: float, details: dict, label: int):\n",
        "    if gemini_model is None:\n",
        "        return \"Gemini API key not set; skipping LLM explanation.\"\n",
        "    risk = \"HIGH\" if prob_phish > 0.7 else \"MODERATE\" if prob_phish > 0.4 else \"LOW\"\n",
        "    evidence_lines = []\n",
        "    if details.get(\"urgency_hits\"):\n",
        "        evidence_lines.append(f\"Urgency words: {', '.join(details['urgency_hits'][:3])}\")\n",
        "    if details.get(\"cred_hits\"):\n",
        "        evidence_lines.append(f\"Credential/payment words: {', '.join(details['cred_hits'][:3])}\")\n",
        "    if details.get(\"urls\"):\n",
        "        evidence_lines.append(f\"Links: {', '.join(details['urls'][:2])}\")\n",
        "    if details.get(\"ip_links\"):\n",
        "        evidence_lines.append(\"Contains IP-based link(s)\")\n",
        "    if details.get(\"caps_words\"):\n",
        "        evidence_lines.append(f\"ALL CAPS words like {', '.join(details['caps_words'][:3])}\")\n",
        "    if not evidence_lines:\n",
        "        evidence_lines.append(\"No obvious phishing indicators detected.\")\n",
        "    prompt = (\n",
        "        \"You are a cybersecurity assistant explaining phishing detections.\\n\\n\"\n",
        "        f\"Email text (truncated):\\n\\\"{email_text[:500]}\\\"\\n\\n\"\n",
        "        f\"Model decision: {'PHISHING' if label == 1 else 'BENIGN'}\\n\"\n",
        "        f\"Model probability of phishing: {prob_phish:.2f}\\n\"\n",
        "        f\"Risk level: {risk}\\n\\n\"\n",
        "        \"Evidence:\\n- \" + \"\\n- \".join(evidence_lines) + \"\\n\\n\"\n",
        "        \"Write 1-2 short sentences for a non-technical user:\\n\"\n",
        "        \"1) Summarize the risk with emoji (red/yellow/green).\\n\"\n",
        "        \"2) Briefly explain why (urgency, credential asks, suspicious links).\\n\"\n",
        "        \"3) Give one clear recommended action.\\n\\n\"\n",
        "        \"Stay under 80 words.\"\n",
        "    )\n",
        "    try:\n",
        "        resp = gemini_model.generate_content(prompt)\n",
        "        return resp.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Could not generate explanation: {e}\"\n",
        "\n",
        "\n",
        "def classify_and_explain(email_text: str):\n",
        "    f_vec, details = feature_extractor.extract_all(email_text)\n",
        "    f_arr = np.array(list(f_vec.values()), dtype=float).reshape(1, -1)\n",
        "    emb_vec = sentence_model.encode([email_text])\n",
        "    x_hybrid = np.hstack([f_arr, emb_vec])\n",
        "    prob_phish = best_model.predict_proba(x_hybrid)[0, 1]\n",
        "    label = int(prob_phish >= 0.5)\n",
        "    return {\n",
        "        \"label\": \"phishing\" if label == 1 else \"benign\",\n",
        "        \"prob_phish\": prob_phish,\n",
        "        \"risk\": \"HIGH\" if prob_phish > 0.7 else \"MODERATE\" if prob_phish > 0.4 else \"LOW\",\n",
        "        \"details\": details,\n",
        "        \"explanation\": gemini_explain(email_text, prob_phish, details, label),\n",
        "    }\n",
        "\n",
        "# ===============================================================\n",
        "# 9. EXAMPLE EXPLANATIONS ON TEST SET\n",
        "# ===============================================================\n",
        "\n",
        "test_df = pd.DataFrame({\"email\": X_test_email, \"label\": y_test})\n",
        "phish_examples = test_df[test_df[\"label\"] == 1].head(3)\n",
        "benign_examples = test_df[test_df[\"label\"] == 0].head(2)\n",
        "examples = pd.concat([phish_examples, benign_examples])\n",
        "\n",
        "for idx, row in examples.iterrows():\n",
        "    print(\"\\n\" + \"-\" * 60)\n",
        "    print(\"EMAIL PREVIEW:\\n\", row[\"email\"][:400], \"...\\n\")\n",
        "    res = classify_and_explain(row[\"email\"])\n",
        "    print(f\"True label : {'phishing' if row['label'] == 1 else 'benign'}\")\n",
        "    print(f\"Predicted  : {res['label']} (p={res['prob_phish']:.2f}, risk={res['risk']})\")\n",
        "    print(f\"\\nGemini explanation:\\n{res['explanation']}\")\n",
        "\n",
        "print(\"\\nPipeline complete (cached artifacts in\", ARTIFACT_DIR, \")\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jak4XWzdZSMJ"
      },
      "source": [
        "Phase 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuOpMOcjBZAQ"
      },
      "source": [
        "## Deployment + caching (Colab + FAISS)\n",
        "- Mount Google Drive (e.g., `/content/drive`) and set `ARTIFACT_DIR = Path(\"/content/drive/MyDrive/phishing_ai\")` to persist models, FAISS index, and splits.\n",
        "- Set `GEMINI_API_KEY` in the env (`%env GEMINI_API_KEY=...`) before running explanation cells; do not hard-code keys.\n",
        "- Install extras if needed: `pip install -q faiss-gpu joblib google-generativeai` (Colab has CUDA wheels).\n",
        "- Run the FAISS cell after embeddings are created; it saves `minilm.index` and id maps so reruns can reload instead of rebuilding.\n",
        "- Header analysis + adversarial tests below can be run independently after training; they do not require dataset reload.\n",
        "- For Gmail forwarding tests, copy the raw headers from Gmail (Show original) and paste into the `raw_headers` string when calling `classify_email_with_headers`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYgib5WJBZAQ"
      },
      "source": [
        "### Header / sender analysis (Reply-To, domain similarity, SPF/DMARC)\n",
        "Use these helpers with pasted raw headers from Gmail/Outlook. They augment the text model with header heuristics for higher-fidelity phishing checks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I4yjpefBZAQ"
      },
      "execution_count": 6,
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# HEADER / SENDER ANALYSIS (Reply-To mismatch, domain similarity, SPF/DMARC)\n",
        "# ===============================================================\n",
        "import re\n",
        "import difflib\n",
        "from email.utils import parseaddr\n",
        "\n",
        "def _domain_from(addr: str) -> str:\n",
        "    name, email_addr = parseaddr(addr)\n",
        "    if \"@\" in email_addr:\n",
        "        return email_addr.split(\"@\")[-1].lower().strip()\n",
        "    return \"\"\n",
        "\n",
        "def _similarity(a: str, b: str) -> float:\n",
        "    a = a.lower().strip()\n",
        "    b = b.lower().strip()\n",
        "    if not a or not b:\n",
        "        return 0.0\n",
        "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "def analyze_headers(raw_headers: str):\n",
        "    hdr_map = {}\n",
        "    for line in raw_headers.splitlines():\n",
        "        if \":\" in line:\n",
        "            k, v = line.split(\":\", 1)\n",
        "            hdr_map[k.strip()] = v.strip()\n",
        "\n",
        "    from_hdr = hdr_map.get(\"From\", \"\")\n",
        "    reply_hdr = hdr_map.get(\"Reply-To\") or hdr_map.get(\"Reply-to\", \"\")\n",
        "    return_hdr = hdr_map.get(\"Return-Path\", \"\")\n",
        "    auth_results = hdr_map.get(\"Authentication-Results\", \"\")\n",
        "    auth_blob = auth_results + \"\\n\" + raw_headers\n",
        "\n",
        "    from_domain = _domain_from(from_hdr)\n",
        "    reply_domain = _domain_from(reply_hdr)\n",
        "    return_domain = _domain_from(return_hdr)\n",
        "\n",
        "    evidence = []\n",
        "    risk = 0\n",
        "\n",
        "    if reply_domain and from_domain and reply_domain != from_domain:\n",
        "        risk += 1\n",
        "        sim = _similarity(from_domain, reply_domain)\n",
        "        evidence.append(f\"Reply-To domain {reply_domain} differs from From {from_domain} (sim={sim:.2f})\")\n",
        "\n",
        "    if return_domain and from_domain and return_domain != from_domain:\n",
        "        risk += 1\n",
        "        evidence.append(f\"Return-Path domain {return_domain} differs from From {from_domain}\")\n",
        "\n",
        "    spf_fail = bool(re.search(r\"spf=(fail|softfail|neutral|none|permerror|temperror)\", auth_blob, re.I) or re.search(r\"Received-SPF:\\s*(fail|softfail|neutral|none|permerror|temperror)\", auth_blob, re.I))\n",
        "    spf_pass = bool(re.search(r\"spf=pass\", auth_blob, re.I) or re.search(r\"Received-SPF:\\s*pass\", auth_blob, re.I))\n",
        "    dmarc_fail = bool(re.search(r\"dmarc=(fail|quarantine|reject)\", auth_blob, re.I))\n",
        "    dmarc_pass = bool(re.search(r\"dmarc=pass\", auth_blob, re.I))\n",
        "\n",
        "    if spf_fail:\n",
        "        risk += 1\n",
        "        evidence.append(\"SPF failed or is neutral/none\")\n",
        "    if dmarc_fail:\n",
        "        risk += 1\n",
        "        evidence.append(\"DMARC failed or is in quarantine/reject\")\n",
        "\n",
        "    verdict = \"low\"\n",
        "    if risk >= 2:\n",
        "        verdict = \"high\"\n",
        "    elif risk == 1:\n",
        "        verdict = \"medium\"\n",
        "\n",
        "    return {\n",
        "        \"from_domain\": from_domain,\n",
        "        \"reply_to_domain\": reply_domain,\n",
        "        \"return_path_domain\": return_domain,\n",
        "        \"spf_pass\": spf_pass,\n",
        "        \"dmarc_pass\": dmarc_pass,\n",
        "        \"risk_level\": verdict,\n",
        "        \"risk_score\": risk,\n",
        "        \"evidence\": evidence,\n",
        "        \"auth_results_snippet\": auth_blob[:400],\n",
        "    }\n",
        "\n",
        "def classify_email_with_headers(email_text: str, raw_headers: str = \"\"):\n",
        "    \"\"\"\n",
        "    Wrapper for end-to-end inference + header heuristics.\n",
        "    Paste raw headers from Gmail/Outlook into `raw_headers` for extra signals.\n",
        "    \"\"\"\n",
        "    base = classify_and_explain(email_text)\n",
        "    hdr = analyze_headers(raw_headers or \"\")\n",
        "    combined_prob = min(1.0, base[\"prob_phish\"] + 0.08 * hdr[\"risk_score\"])\n",
        "    combined_label = \"phishing\" if combined_prob >= 0.5 else \"benign\"\n",
        "    base.update({\n",
        "        \"header_analysis\": hdr,\n",
        "        \"combined_prob_phish\": combined_prob,\n",
        "        \"combined_label\": combined_label,\n",
        "    })\n",
        "    return base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXHGMDnYBZAR"
      },
      "source": [
        "### Adversarial low-signal phishing tests\n",
        "Use these to sanity-check the model on grammatically clean, low-signal phish (no typos, minimal urgency cues).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "7X6kGWRBBZAR",
        "outputId": "d54f6f0f-6b34-4977-aa0a-fc50ecb2653e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Adversarial spot-checks:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.87ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "Quick heads up: payroll could not process your details. Please confirm your direct deposit info before 5pm today.\n",
            "Model: benign (p=0.35, risk=LOW) -> combined=benign (p=0.35)\n",
            "Header flags: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 352.57ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "We could not verify your Microsoft 365 account. Review the document in the secure portal before access is suspended: http://contoso-verify.com/login\n",
            "Model: phishing (p=0.90, risk=HIGH) -> combined=phishing (p=0.90)\n",
            "Header flags: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 327.60ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "Reminder: HR policy update requires your acknowledgment. Open the attached PDF to keep access active.\n",
            "Model: benign (p=0.05, risk=LOW) -> combined=benign (p=0.05)\n",
            "Header flags: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 327.95ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "Travel receipt pending: upload the attached CSV to clear your card hold.\n",
            "Model: benign (p=0.37, risk=LOW) -> combined=benign (p=0.37)\n",
            "Header flags: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:403 POST /v1beta/models/gemini-2.5-flash-lite:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 354.08ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "Security notice: unusual login from a new device. If this was you, ignore; otherwise confirm at https://accounts-security-check.com\n",
            "Model: phishing (p=0.81, risk=HIGH) -> combined=phishing (p=0.81)\n",
            "Header flags: []\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# ADVERSARIAL LOW-SIGNAL PHISHING TESTS\n",
        "# ===============================================================\n",
        "adversarial_samples = [\n",
        "    \"Quick heads up: payroll could not process your details. Please confirm your direct deposit info before 5pm today.\",\n",
        "    \"We could not verify your Microsoft 365 account. Review the document in the secure portal before access is suspended: http://contoso-verify.com/login\",\n",
        "    \"Reminder: HR policy update requires your acknowledgment. Open the attached PDF to keep access active.\",\n",
        "    \"Travel receipt pending: upload the attached CSV to clear your card hold.\",\n",
        "    \"Security notice: unusual login from a new device. If this was you, ignore; otherwise confirm at https://accounts-security-check.com\",\n",
        "]\n",
        "\n",
        "print(\"\\nAdversarial spot-checks:\")\n",
        "for txt in adversarial_samples:\n",
        "    res = classify_email_with_headers(txt)\n",
        "    print(\"\\n---\")\n",
        "    print(txt)\n",
        "    print(f\"Model: {res['label']} (p={res['prob_phish']:.2f}, risk={res['risk']}) -> combined={res['combined_label']} (p={res['combined_prob_phish']:.2f})\")\n",
        "    print(\"Header flags:\", res[\"header_analysis\"][\"evidence\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSrqglhBZAR"
      },
      "source": [
        "### FAISS neighbor index (persist to Drive)\n",
        "Build or load a FAISS index on MiniLM embeddings for fast nearest-neighbor lookups in explanations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQE7yghJBZAR"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# FAISS NEIGHBOR INDEX (build/save/load) - optional\n",
        "# ===============================================================\n",
        "try:\n",
        "    import faiss\n",
        "    FAISS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    FAISS_AVAILABLE = False\n",
        "    print(\"Install faiss-gpu to enable FAISS neighbor search and run this cell again.\")\n",
        "\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "\n",
        "ARTIFACT_DIR = Path(\"/content/drive/MyDrive/phishing_ai\").expanduser()\n",
        "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "faiss_index_path = ARTIFACT_DIR / \"minilm.index\"\n",
        "train_ids_path = ARTIFACT_DIR / \"train_ids.npy\"\n",
        "model_path = ARTIFACT_DIR / \"calibrated_model.joblib\"\n",
        "\n",
        "if FAISS_AVAILABLE:\n",
        "    if faiss_index_path.exists():\n",
        "        faiss_index = faiss.read_index(str(faiss_index_path))\n",
        "        print(\"Loaded FAISS index from\", faiss_index_path, \"(ntotal=\", faiss_index.ntotal, \")\")\n",
        "    elif \"X_train_emb\" in globals():\n",
        "        train_emb = X_train_emb.astype(\"float32\").copy()\n",
        "        faiss.normalize_L2(train_emb)\n",
        "        faiss_index = faiss.IndexFlatIP(train_emb.shape[1])\n",
        "        faiss_index.add(train_emb)\n",
        "        faiss.write_index(faiss_index, str(faiss_index_path))\n",
        "        np.save(train_ids_path, np.arange(train_emb.shape[0], dtype=np.int32))\n",
        "        print(\"FAISS index built and saved to\", ARTIFACT_DIR)\n",
        "    else:\n",
        "        print(\"Embeddings not in memory; run the encoding cell before building FAISS.\")\n",
        "\n",
        "def faiss_neighbors(query_texts, k=5):\n",
        "    if not FAISS_AVAILABLE:\n",
        "        raise RuntimeError(\"FAISS not available; install faiss-gpu and rerun the build cell.\")\n",
        "    if \"faiss_index\" not in globals():\n",
        "        raise RuntimeError(\"FAISS index not loaded; build or load it first.\")\n",
        "    q_emb = sentence_model.encode(list(query_texts), convert_to_numpy=True, normalize_embeddings=True)\n",
        "    scores, idx = faiss_index.search(q_emb.astype(\"float32\"), k)\n",
        "    return scores, idx\n",
        "\n",
        "if \"best_model\" in globals():\n",
        "    joblib.dump(best_model, model_path)\n",
        "    print(\"Saved calibrated model to\", model_path)\n",
        "else:\n",
        "    print(\"best_model not in memory; train first to save.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}